# ç¬¬ä¸€è½®é¢è¯•å¤ä¹ ææ–™

## ğŸ“š Kubernetesæ ¸å¿ƒçŸ¥è¯†

### 1. CRD (Custom Resource Definition) åŸºç¡€

#### ä»€ä¹ˆæ˜¯CRDï¼Ÿ
CRDå…è®¸ç”¨æˆ·åœ¨Kubernetesä¸­å®šä¹‰è‡ªå·±çš„èµ„æºç±»å‹ï¼Œæ‰©å±•Kubernetes APIã€‚

#### CRDç¤ºä¾‹
```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: appservices.app.example.com
spec:
  group: app.example.com
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              replicas:
                type: integer
              image:
                type: string
  scope: Namespaced
  names:
    plural: appservices
    singular: appservice
    kind: AppService
```

### 2. Operatorå¼€å‘æ¡†æ¶

#### Kubebuilder vs Operator-SDKå¯¹æ¯”
| ç‰¹æ€§ | Kubebuilder | Operator-SDK |
|------|------------|--------------|
| è¯­è¨€æ”¯æŒ | Go | Go, Ansible, Helm |
| å­¦ä¹ æ›²çº¿ | ä¸­ç­‰ | è¾ƒä½ |
| ç¤¾åŒºæ”¯æŒ | Kuberneteså®˜æ–¹ | RedHat/CoreOS |
| è„šæ‰‹æ¶ | å®Œå–„ | æ›´ä¸°å¯Œ |

#### Controlleræ ¸å¿ƒç»„ä»¶
```go
// Reconcileæ ¸å¿ƒé€»è¾‘
func (r *AppServiceReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    // 1. è·å–CRå¯¹è±¡
    appService := &appv1.AppService{}
    if err := r.Get(ctx, req.NamespacedName, appService); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }
    
    // 2. å¤„ç†åˆ é™¤
    if !appService.DeletionTimestamp.IsZero() {
        return r.handleDeletion(ctx, appService)
    }
    
    // 3. ç¡®ä¿Deploymentå­˜åœ¨
    deployment := r.constructDeployment(appService)
    if err := r.createOrUpdate(ctx, deployment); err != nil {
        return ctrl.Result{}, err
    }
    
    // 4. æ›´æ–°çŠ¶æ€
    appService.Status.Ready = r.isDeploymentReady(deployment)
    if err := r.Status().Update(ctx, appService); err != nil {
        return ctrl.Result{}, err
    }
    
    return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
}
```

### 3. Kubernetesç½‘ç»œçŸ¥è¯†

#### ç½‘ç»œæ¨¡å‹
- **Cluster IP**: é›†ç¾¤å†…éƒ¨è®¿é—®
- **NodePort**: èŠ‚ç‚¹ç«¯å£æš´éœ²ï¼ˆ30000-32767ï¼‰
- **LoadBalancer**: äº‘å‚å•†è´Ÿè½½å‡è¡¡å™¨
- **Ingress**: 7å±‚è·¯ç”±

#### ç½‘ç»œç­–ç•¥ç¤ºä¾‹
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080
```

## ğŸ’» Goè¯­è¨€é‡ç‚¹

### 1. å¹¶å‘æ¨¡å¼

#### Worker Poolæ¨¡å¼
```go
package main

import (
    "context"
    "sync"
)

type WorkerPool struct {
    workerCount int
    jobs        chan Job
    results     chan Result
    wg          sync.WaitGroup
}

type Job struct {
    ID   int
    Data interface{}
}

type Result struct {
    JobID int
    Data  interface{}
    Err   error
}

func NewWorkerPool(workerCount int) *WorkerPool {
    return &WorkerPool{
        workerCount: workerCount,
        jobs:        make(chan Job, workerCount*2),
        results:     make(chan Result, workerCount*2),
    }
}

func (p *WorkerPool) Start(ctx context.Context) {
    for i := 0; i < p.workerCount; i++ {
        p.wg.Add(1)
        go p.worker(ctx, i)
    }
}

func (p *WorkerPool) worker(ctx context.Context, id int) {
    defer p.wg.Done()
    
    for {
        select {
        case job, ok := <-p.jobs:
            if !ok {
                return
            }
            // å¤„ç†ä»»åŠ¡
            result := p.process(job)
            p.results <- result
            
        case <-ctx.Done():
            return
        }
    }
}

func (p *WorkerPool) process(job Job) Result {
    // å®é™…çš„ä¸šåŠ¡é€»è¾‘
    return Result{JobID: job.ID}
}
```

### 2. é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```go
// è‡ªå®šä¹‰é”™è¯¯ç±»å‹
type OpError struct {
    Op   string
    Kind string
    Err  error
}

func (e *OpError) Error() string {
    return fmt.Sprintf("operation %s failed on %s: %v", e.Op, e.Kind, e.Err)
}

func (e *OpError) Unwrap() error {
    return e.Err
}

// é”™è¯¯åŒ…è£…
func doSomething() error {
    if err := callAPI(); err != nil {
        return &OpError{
            Op:   "doSomething",
            Kind: "API",
            Err:  err,
        }
    }
    return nil
}
```

## ğŸ–¥ï¸ GPUèµ„æºç®¡ç†åŸºç¡€

### NVIDIA GPUåœ¨Kubernetesä¸­çš„ä½¿ç”¨

#### 1. Device Pluginéƒ¨ç½²
```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  template:
    spec:
      containers:
      - image: nvidia/k8s-device-plugin:v0.12.0
        name: nvidia-device-plugin-ctr
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
        - name: device-plugin
          mountPath: /var/lib/kubelet/device-plugins
```

#### 2. Podè¯·æ±‚GPUèµ„æº
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
  - name: cuda-container
    image: nvidia/cuda:11.0-base
    resources:
      limits:
        nvidia.com/gpu: 2 # è¯·æ±‚2ä¸ªGPU
```

### GPUè°ƒåº¦ç­–ç•¥
- **ç‹¬å æ¨¡å¼**: ä¸€ä¸ªGPUåªèƒ½è¢«ä¸€ä¸ªPodä½¿ç”¨
- **å…±äº«æ¨¡å¼**: é€šè¿‡MIG(Multi-Instance GPU)æŠ€æœ¯å…±äº«
- **æ—¶åˆ†å¤ç”¨**: é€šè¿‡è°ƒåº¦å™¨å®ç°GPUæ—¶é—´ç‰‡å…±äº«

## ğŸ”§ ç›‘æ§å‘Šè­¦å®è·µ

### Prometheusé…ç½®ç¤ºä¾‹
```yaml
# prometheus-config.yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
```

### è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™
```yaml
groups:
- name: example
  rules:
  - alert: HighMemoryUsage
    expr: container_memory_usage_bytes{pod!=""} / container_spec_memory_limit_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Pod {{ $labels.pod }} memory usage is above 90%"
      description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} memory usage is {{ $value | humanizePercentage }}"
```

## ğŸ“ é¢è¯•å¸¸è§é—®é¢˜é€ŸæŸ¥

### Kubernetesç›¸å…³
1. **Podç”Ÿå‘½å‘¨æœŸ**: Pending â†’ Running â†’ Succeeded/Failed
2. **Serviceç±»å‹**: ClusterIP, NodePort, LoadBalancer, ExternalName
3. **å­˜å‚¨ç±»å‹**: emptyDir, hostPath, PV/PVC, ConfigMap, Secret
4. **è°ƒåº¦ç­–ç•¥**: nodeSelector, nodeAffinity, podAffinity, taints/tolerations

### Goè¯­è¨€ç›¸å…³
1. **å¹¶å‘åŸè¯­**: goroutine, channel, select, syncåŒ…
2. **å†…å­˜ç®¡ç†**: æ ˆåˆ†é…vså †åˆ†é…, é€ƒé€¸åˆ†æ
3. **GCä¼˜åŒ–**: GOGCè®¾ç½®, sync.Poolä½¿ç”¨
4. **æ€§èƒ½åˆ†æ**: pprof, trace, benchmark

### ç½‘ç»œç›¸å…³
1. **OSIä¸ƒå±‚æ¨¡å‹**: ç‰©ç†å±‚â†’æ•°æ®é“¾è·¯å±‚â†’ç½‘ç»œå±‚â†’ä¼ è¾“å±‚â†’ä¼šè¯å±‚â†’è¡¨ç¤ºå±‚â†’åº”ç”¨å±‚
2. **TCPä¸‰æ¬¡æ¡æ‰‹**: SYN â†’ SYN-ACK â†’ ACK
3. **Linuxç½‘ç»œå‘½ä»¤**: tcpdump, netstat, ss, ip, iptables

## ğŸ¯ å®æˆ˜é¡¹ç›®å‡†å¤‡å»ºè®®

### é¡¹ç›®æ¡ˆä¾‹æ¨¡æ¿
```
é¡¹ç›®åç§°ï¼šXXXè‡ªåŠ¨åŒ–è¿ç»´å¹³å°
é¡¹ç›®èƒŒæ™¯ï¼š
- ç®¡ç†è§„æ¨¡ï¼š500+èŠ‚ç‚¹çš„Kubernetesé›†ç¾¤
- æ—¥å‡å¤„ç†ï¼š10ä¸‡+å®¹å™¨è°ƒåº¦è¯·æ±‚
- æœåŠ¡å¯¹è±¡ï¼š50+ç ”å‘å›¢é˜Ÿ

æŠ€æœ¯æ–¹æ¡ˆï¼š
- æ¶æ„ï¼šå¾®æœåŠ¡æ¶æ„ï¼ŒGoè¯­è¨€å¼€å‘
- æ ¸å¿ƒç»„ä»¶ï¼šè‡ªå®šä¹‰Operatorã€è°ƒåº¦å™¨ã€ç›‘æ§å‘Šè­¦
- æŠ€æœ¯æ ˆï¼šGo + Kubernetes + Prometheus + Grafana

é¡¹ç›®æˆæœï¼š
- éƒ¨ç½²æ•ˆç‡æå‡300%
- æ•…éšœæ¢å¤æ—¶é—´ä»å°æ—¶çº§é™åˆ°åˆ†é’Ÿçº§
- èµ„æºåˆ©ç”¨ç‡æå‡40%

ä¸ªäººè´¡çŒ®ï¼š
- è´Ÿè´£Operatorå¼€å‘
- è®¾è®¡è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥
- ä¼˜åŒ–è°ƒåº¦ç®—æ³•
```

## ä¸‹ä¸€æ­¥å­¦ä¹ è®¡åˆ’
1. æ·±å…¥å­¦ä¹ Kubernetesæºç 
2. å®è·µCRD/Operatorå¼€å‘é¡¹ç›®
3. äº†è§£GPUè™šæ‹ŸåŒ–æŠ€æœ¯
4. å­¦ä¹ æœåŠ¡ç½‘æ ¼(Istio/Linkerd)
5. æŒæ¡GitOpså®è·µ(ArgoCD/Flux) 